import streamlit as st
import pandas as pd
import streamlit.components.v1 as components
import json
import httpx  # For making asynchronous API calls
import asyncio
import yaml

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="AI Hat Design Studio",
    page_icon="ğŸ‘’",
    layout="wide"
)

# --- ë£¨ë¯¸ë‚˜: ì•±ì˜ ë¹„ì „ê³¼ ì‚¬ìš©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤ ---
st.title("ğŸ‘’ AI ëª¨ì ë””ìì¸ ìŠ¤íŠœë””ì˜¤ v1.2 (Live & Secure)")
st.markdown("""
**ì§„ì§œ Gemini AI ì—”ì§„ì´ ì•ˆì „í•˜ê²Œ ë‚´ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!**
ì´ì œ 'Forma'ëŠ” ë‹¹ì‹ ì˜ ììœ ë¡œìš´ ë§ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì´í•´í•˜ê³ , ê·¸ì— ë§ì¶° 3D ëª¨ë¸ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.
BOM ë°ì´í„°ë¥¼ ì˜¬ë¦¬ê³ , ì´ˆê¸° ëª¨ë¸ì„ ì¡°ë¦½í•œ ë’¤, ì±„íŒ…ì°½ì— ììœ ë¡­ê²Œ ëª…ë ¹ì„ ë‚´ë ¤ë³´ì„¸ìš”.
""")

# --- ë¸íƒ€: ì‹œìŠ¤í…œì˜ í•µì‹¬ ë¡œì§ì„ êµ¬í˜„í•©ë‹ˆë‹¤ ---

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'hat_config' not in st.session_state:
    st.session_state.hat_config = {
        "parts": [], "logo_scale": 1.0, "brim_color": "#808080"
    }

# --- FIX: API í‚¤ë¥¼ ê°€ì¥ ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤ ---
# Streamlit Cloudì˜ 'Secrets'ì—ì„œ API í‚¤ë¥¼ ì§ì ‘ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
# ì´ì œ ë” ì´ìƒ ì‚¬ìš©ìì—ê²Œ í‚¤ë¥¼ ë¬»ê±°ë‚˜, ì½”ë“œì— í‚¤ë¥¼ ë…¸ì¶œí•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
api_key = st.secrets.get("GOOGLE_AI_API_KEY")

# --- ë°ì´í„° ë° í˜ë¥´ì†Œë‚˜ ë¡œë”© ---
@st.cache_data
def load_assets():
    try:
        bom_df = pd.read_csv('bom_data.csv')
        bom_df.columns = bom_df.columns.str.strip().str.lower()
    except FileNotFoundError:
        st.error("bom_data.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    try:
        with open('persona_forma.yml', 'r', encoding='utf-8') as f:
            persona_config = yaml.safe_load(f)
    except FileNotFoundError:
        st.error("persona_forma.yml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    return bom_df, persona_config

bom_df, persona_config = load_assets()


# --- LLM ì—°ë™ì„ ìœ„í•œ ë¹„ë™ê¸° í•¨ìˆ˜ ---
async def parse_command_with_llm(command, key, persona, available_parts):
    if not key:
        st.error("Google AI API Keyê°€ Streamlit Secretsì— ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•± ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        return None

    # í˜ë¥´ì†Œë‚˜ì™€ ì§€ì‹ì„ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…
    persona_prompt = f"""
    You are {persona.get('role', 'an AI assistant')}.
    Your personality is: {persona.get('personality', 'helpful')}.
    Your core directives are: {json.dumps(persona.get('core_directives', []))}.
    You have the following capabilities: {json.dumps(persona.get('capabilities', []))}.
    You have this knowledge base for styles: {json.dumps(persona.get('knowledge_base', []))}.
    You have these parts available to you: {json.dumps(available_parts)}.

    Your task is to translate the user's command into a single, valid JSON object based on your capabilities.
    
    User command: "{command}"
    
    JSON Action:
    """
    
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={key}"
    payload = {"contents": [{"role": "user", "parts": [{"text": persona_prompt}]}]}

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(api_url, json=payload, timeout=30)
            response.raise_for_status()
            result = response.json()
            raw_text = result['candidates'][0]['content']['parts'][0]['text']
            clean_text = raw_text.strip().replace("```json", "").replace("```", "").strip()
            return json.loads(clean_text)
    except Exception as e:
        st.error(f"LLM API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# 1. BoMi: BOM ë¶„ì„ íŒŒíŠ¸
st.header("Step 1: 'BoMi' - ë¶€í’ˆ ì„ íƒ")
uploaded_file = st.file_uploader("BOM ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (CSV)", type=["csv"])

if uploaded_file is not None:
    try:
        # Use the uploaded file instead of the cached one if provided
        bom_df = pd.read_csv(uploaded_file)
        bom_df.columns = bom_df.columns.str.strip().str.lower()
        
        st.subheader("ì„ íƒëœ ë¶€í’ˆ ë¦¬ìŠ¤íŠ¸")
        st.dataframe(bom_df)

        if st.button("ì´ˆê¸° ëª¨ë¸ ì¡°ë¦½í•˜ê¸°", key="initial_assembly"):
            with st.spinner("'Forma'ê°€ ì´ˆê¸° ëª¨ë¸ì„ ì¡°ë¦½í•©ë‹ˆë‹¤..."):
                parts_to_load = []
                for index, row in bom_df.iterrows():
                    parts_to_load.append({"type": row['part_type'], "model_file": row['model_file']})
                st.session_state.hat_config['parts'] = parts_to_load
                st.success("ì´ˆê¸° ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ì±„íŒ…ì°½ì— ììœ ë¡­ê²Œ ëª…ë ¹ì„ ë‚´ë ¤ë³´ì„¸ìš”.")
    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# 2. Forma: 3D ì¡°ë¦½ ë° ëŒ€í™”í˜• ìˆ˜ì • íŒŒíŠ¸
if st.session_state.hat_config['parts']:
    st.markdown("---")
    st.header("Step 2: 'Forma' - ëŒ€í™”í˜• ë””ìì¸")
    command = st.text_input("Formaì—ê²Œ ììœ ë¡­ê²Œ ëª…ë ¹ì„ ë‚´ë¦¬ì„¸ìš” (ì˜ˆ: 'make it a cowboy hat')")

    if command:
        if not api_key:
            st.warning("Google AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„, LLM ì—°ë™ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            available_parts_list = bom_df.to_dict('records') if bom_df is not None else []
            parsed_command = asyncio.run(parse_command_with_llm(command, api_key, persona_config, available_parts_list))
            
            if parsed_command:
                action = parsed_command.get("action")
                if action == "change_property":
                    target = parsed_command.get("target")
                    prop = parsed_command.get("property")
                    val = parsed_command.get("value")
                    if target == 'logo' and prop == 'scale':
                        st.session_state.hat_config['logo_scale'] = float(val)
                        st.success(f"ëª…ë ¹ ì´í•´: ë¡œê³  ìŠ¤ì¼€ì¼ {val}ë¡œ ë³€ê²½")
                    elif target == 'brim' and prop == 'color':
                        color_map = {"red": "#ff0000", "blue": "#0000ff", "green": "#008000", "black": "#000000"}
                        st.session_state.hat_config['brim_color'] = color_map.get(str(val).lower(), "#808080")
                        st.success(f"ëª…ë ¹ ì´í•´: ì±™ ìƒ‰ìƒ {val}ë¡œ ë³€ê²½")
                elif action == "change_part":
                    part_type = parsed_command.get("part_type")
                    new_model = parsed_command.get("new_model_file")
                    # ì„¸ì…˜ ìƒíƒœì˜ ë¶€í’ˆ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                    for part in st.session_state.hat_config['parts']:
                        if part['type'].lower() == part_type.lower():
                            part['model_file'] = new_model
                            break
                    st.success(f"ëª…ë ¹ ì´í•´: {part_type}ì„(ë¥¼) {new_model}ë¡œ êµì²´")
                
                # Re-render the component by rerunning the script
                st.experimental_rerun()

    # 3D ë·°ì–´ ë Œë”ë§
    with st.container():
        github_user = "HWAN-OH"
        github_repo = "AI-Hat-Design-Studio"
        base_url = f"https://raw.githubusercontent.com/{github_user}/{github_repo}/main/models/"
        models_to_load = []
        for part in st.session_state.hat_config['parts']:
             models_to_load.append({"type": part['type'], "url": base_url + part['model_file']})
        config_json = json.dumps(st.session_state.hat_config)
        html_code = f"""
            <!DOCTYPE html><html><head><style>body{{margin:0;}}canvas{{display:block;}}</style></head>
            <body>
                <script type="importmap">{{"imports":{{"three":"https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js","three/addons/":"https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/"}}}}</script>
                <script type="module">
                    import * as THREE from 'three';
                    import {{GLTFLoader}} from 'three/addons/loaders/GLTFLoader.js';
                    import {{OrbitControls}} from 'three/addons/controls/OrbitControls.js';
                    const scene=new THREE.Scene();scene.background=new THREE.Color(0xf0f2f5);
                    const camera=new THREE.PerspectiveCamera(75,window.innerWidth/window.innerHeight,0.1,1000);camera.position.set(0,0.1,0.5);
                    const renderer=new THREE.WebGLRenderer({{antialias:true}});renderer.setSize(window.innerWidth,window.innerHeight);document.body.appendChild(renderer.domElement);
                    const ambientLight=new THREE.AmbientLight(0xffffff,1.5);scene.add(ambientLight);
                    const directionalLight=new THREE.DirectionalLight(0xffffff,2);directionalLight.position.set(1,1,1);scene.add(directionalLight);
                    const controls=new OrbitControls(camera,renderer.domElement);
                    const hatConfig={config_json};const models={json.dumps(models_to_load)};
                    const loader=new GLTFLoader();const hatParts=new THREE.Group();scene.add(hatParts);
                    models.forEach(modelData=>{{loader.load(modelData.url,(gltf)=>{{const model=gltf.scene;
                    if(modelData.type.toLowerCase()==='logo'){{model.scale.setScalar(hatConfig.logo_scale||1.0);}}
                    if(modelData.type.toLowerCase()==='brim'){{model.traverse((child)=>{{if(child.isMesh){{child.material=child.material.clone();child.material.color.set(hatConfig.brim_color||"#808080");}}}});}}
                    hatParts.add(model);}});}});
                    function animate(){{requestAnimationFrame(animate);controls.update();renderer.render(scene,camera);}}
                    animate();
                </script>
            </body></html>
        """
        components.html(html_code, height=600, scrolling=False)

