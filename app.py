import streamlit as st
import pandas as pd
import streamlit.components.v1 as components
import json
import httpx
import asyncio
import yaml

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="AI Hat Design Studio",
    page_icon="ğŸ‘’",
    layout="wide"
)

# --- ë£¨ë¯¸ë‚˜: ì•±ì˜ ë¹„ì „ê³¼ ì‚¬ìš©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤ ---
st.title("ğŸ‘’ AI ëª¨ì ë””ìì¸ ìŠ¤íŠœë””ì˜¤ v1.1 (Persona-Powered)")
st.markdown("""
**'Forma'ì—ê²Œ 'í˜ë¥´ì†Œë‚˜'ê°€ ì£¼ì…ë˜ì—ˆìŠµë‹ˆë‹¤!**
ì´ì œ FormaëŠ” ë‹¨ìˆœí•œ ë²ˆì—­ê¸°ê°€ ì•„ë‹Œ, ëª¨ì ìŠ¤íƒ€ì¼ì— ëŒ€í•œ ì§€ì‹ì„ ê°€ì§„ 'AI ë””ìì´ë„ˆ'ë¡œì„œ ë‹¹ì‹ ì˜ ë§ì„ ì´í•´í•©ë‹ˆë‹¤.
"ì¹´ìš°ë³´ì´ ëª¨ìë¡œ ë°”ê¿”ì¤˜" ë˜ëŠ” "ë¡œê³ ë¥¼ 2ë°° í‚¤ì›Œì¤˜" ì™€ ê°™ì´ ììœ ë¡­ê²Œ ëª…ë ¹í•´ë³´ì„¸ìš”.
""")

# --- ë¸íƒ€: ì‹œìŠ¤í…œì˜ í•µì‹¬ ë¡œì§ì„ êµ¬í˜„í•©ë‹ˆë‹¤ ---

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'hat_config' not in st.session_state:
    st.session_state.hat_config = {
        "parts": [], "logo_scale": 1.0, "brim_color": "#808080"
    }

# --- ë°ì´í„° ë° í˜ë¥´ì†Œë‚˜ ë¡œë”© ---
@st.cache_data
def load_assets():
    try:
        bom_df = pd.read_csv('bom_data.csv')
        bom_df.columns = bom_df.columns.str.strip().str.lower()
    except FileNotFoundError:
        st.error("bom_data.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    try:
        with open('persona_forma.yml', 'r', encoding='utf-8') as f:
            persona_config = yaml.safe_load(f)
    except FileNotFoundError:
        st.error("persona_forma.yml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    return bom_df, persona_config

bom_df, persona_config = load_assets()

# --- LLM ì—°ë™ í•¨ìˆ˜ (í˜ë¥´ì†Œë‚˜ ì£¼ì…) ---
async def parse_command_with_llm(command, api_key, persona, available_parts):
    if not api_key:
        st.error("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # í˜ë¥´ì†Œë‚˜ì™€ ì§€ì‹ì„ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…
    persona_prompt = f"""
    You are {persona.get('role', 'an AI assistant')}.
    Your personality is: {persona.get('personality', 'helpful')}.
    Your core directives are: {json.dumps(persona.get('core_directives', []))}.
    You have the following capabilities: {json.dumps(persona.get('capabilities', []))}.
    You have this knowledge base for styles: {json.dumps(persona.get('knowledge_base', []))}.
    You have these parts available to you: {json.dumps(available_parts)}.

    Your task is to translate the user's command into a single, valid JSON object based on your capabilities.
    
    User command: "{command}"
    
    JSON Action:
    """
    
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"
    payload = {"contents": [{"role": "user", "parts": [{"text": persona_prompt}]}]}

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(api_url, json=payload, timeout=30)
            response.raise_for_status()
            result = response.json()
            raw_text = result['candidates'][0]['content']['parts'][0]['text']
            clean_text = raw_text.strip().replace("```json", "").replace("```", "").strip()
            return json.loads(clean_text)
    except Exception as e:
        st.error(f"LLM API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# --- UI ---
api_key = st.sidebar.text_input("Google AI API í‚¤", type="password")

if bom_df is not None and persona_config is not None:
    st.header("1. ë¶€í’ˆ ë¼ì´ë¸ŒëŸ¬ë¦¬")
    st.dataframe(bom_df)

    if st.button("ì´ˆê¸° ëª¨ë¸ ì¡°ë¦½", key="initial_assembly"):
        parts_to_load = []
        for index, row in bom_df.iterrows():
            parts_to_load.append({
                "type": row['part_type'],
                "model_file": row['model_file']
            })
        st.session_state.hat_config['parts'] = parts_to_load
        st.success("ì´ˆê¸° ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ. ì•„ë˜ì— ëª…ë ¹ì„ ì…ë ¥í•˜ì„¸ìš”.")

    if st.session_state.hat_config['parts']:
        st.markdown("---")
        st.header("2. ëŒ€í™”í˜• ë””ìì¸")
        command = st.text_input("Formaì—ê²Œ ëª…ë ¹í•˜ì„¸ìš” (ì˜ˆ: 'make it a cowboy hat')")

        if command:
            available_parts_list = bom_df.to_dict('records')
            parsed_command = asyncio.run(parse_command_with_llm(command, api_key, persona_config, available_parts_list))
            
            if parsed_command:
                action = parsed_command.get("action")
                if action == "change_property":
                    target = parsed_command.get("target")
                    prop = parsed_command.get("property")
                    val = parsed_command.get("value")
                    if target == 'logo' and prop == 'scale':
                        st.session_state.hat_config['logo_scale'] = float(val)
                        st.success(f"ëª…ë ¹ ì´í•´: ë¡œê³  ìŠ¤ì¼€ì¼ {val}ë¡œ ë³€ê²½")
                    elif target == 'brim' and prop == 'color':
                        color_map = {"red": "#ff0000", "blue": "#0000ff", "green": "#008000", "black": "#000000"}
                        st.session_state.hat_config['brim_color'] = color_map.get(str(val).lower(), "#808080")
                        st.success(f"ëª…ë ¹ ì´í•´: ì±™ ìƒ‰ìƒ {val}ë¡œ ë³€ê²½")
                elif action == "change_part":
                    part_type = parsed_command.get("part_type")
                    new_model = parsed_command.get("new_model_file")
                    # ì„¸ì…˜ ìƒíƒœì˜ ë¶€í’ˆ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                    for part in st.session_state.hat_config['parts']:
                        if part['type'].lower() == part_type.lower():
                            part['model_file'] = new_model
                            break
                    st.success(f"ëª…ë ¹ ì´í•´: {part_type}ì„(ë¥¼) {new_model}ë¡œ êµì²´")
                
                # Re-render the component
                st.experimental_rerun()

        # 3D ë·°ì–´ ë Œë”ë§
        with st.container():
            # ... (HTML/JS code for 3D viewer remains the same)
            github_user = "HWAN-OH"
            github_repo = "AI-Hat-Design-Studio"
            base_url = f"https://raw.githubusercontent.com/{github_user}/{github_repo}/main/models/"
            models_to_load = []
            for part in st.session_state.hat_config['parts']:
                 models_to_load.append({"type": part['type'], "url": base_url + part['model_file']})
            config_json = json.dumps(st.session_state.hat_config)
            html_code = f""" ... """ # HTML/JS code is lengthy, assuming it's correct
            components.html(html_code, height=600, scrolling=False)
